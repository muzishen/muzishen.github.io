<!DOCTYPE html>

<html>

<head>
	<title>Fei Shen</title>

	<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" rel="stylesheet"
		integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

	<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js"
		integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n"
		crossorigin="anonymous"></script>

	<style type="text/css">
		@import url("http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600,600italic");

		body {
			font-family: "Roboto", Helvetica, Arial, sans-serif;
			font-size: 16px;
			line-height: 1.5;
			font-weight: 300;
			background-color: #CDCDCD;
		}

		.content {
			width: 900px;
			padding: 25px 30px;
			margin: 25px auto;
			background-color: #fff;
			box-shadow: 0px 0px 10px #999;
			border-radius: 15px;
		}

		table {
			padding: 5px;
		}

		table.pub_table,
		td.pub_td1,
		td.pub_td2 {
			padding: 8px;
			width: 850px;
			border-collapse: separate;
			border-spacing: 15px;
			margin-top: -5px;
		}

		td.pub_td1 {
			width: 50px;
		}

		td.pub_td1 img {
			height: 120px;
			width: 160px;
		}

		div#container {
			margin-left: auto;
			margin-right: auto;
			width: 820px;
			text-align: left;
			position: relative;
			background-color: #FFF;
		}

		div#DocInfo {
			color: #1367a7;
			height: 158px;
		}

		h4,
		h3,
		h2,
		h1 {
			color: #3B3B3B;
		}

		h2 {
			font-size: 130%;
		}

		p {
			color: #5B5B5B;
			margin-bottom: 50px;
		}

		p.caption {
			color: #9B9B9B;
			text-align: left;
			width: 600px;
		}

		p.caption2 {
			color: #9B9B9B;
			text-align: left;
			width: 800px;
		}

		#header_img {
			position: absolute;
			top: 0px;
			right: 0px;
		}

		a:link,
		a:visited {
			color: #1367a7;
			text-decoration: none;
		}

		#mit_logo {
			position: absolute;
			left: 646px;
			top: 14px;
			width: 200px;
			height: 20px;
		}

		table.pub_table tr {
			outline: thin dotted #666666;
		}

		.papericon {
			border-radius: 8px;
			-moz-box-shadow: 3px 3px 6px #888;
			-webkit-box-shadow: 3px 3px 6px #888;
			box-shadow: 3px 3px 6px #888;
			width: 180px;
			margin-top: 5px;
			margin-left: 5px;
			margin-bottom: 5px;
		}

		.papericon_blank {
			width: 160px;
			margin-top: 5px;
			margin-left: 5px;
			margin-bottom: 5px;
		}

		.media {
			outline: thin dotted #666666;
			margin-bottom: 15px;
			margin-left: 10px;
		}

		.media-body {
			margin-top: 5px;
			padding-left: 20px;
		}

		.papers-selected h5,
		.papers-selected h4 {
			display: none;
		}

		.papers-selected .publication {
			display: none;
		}

		.paperhi-only {
			display: none;
		}

		.papers-selected .paperhi {
			display: flex;
		}

		.papers-selected .paperlo {
			display: none;
		}

		.awards-selected h5,
		.awards-selected h4 {
			display: none;
		}

		.awards-selected .publication {
			display: none;
		}

		.awardhi-only {
			display: none;
		}

		.awards-selected .awardhi {
			display: flex;
		}

		.awards-selected .awardlo {
			display: none;
		}

		.hidden>div {
			display: none;
		}

		.visible>div {
			display: block;
		}
	</style>

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-23931362-2"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag () { dataLayer.push(arguments); }
		gtag('js', new Date());

		gtag('config', 'UA-23931362-2');
	</script>

	<script type="text/javascript">
		var myPix = new Array("img/wechat.png")
		function choosePic () {
			var randomNum = Math.floor(Math.random() * myPix.length);
			document.getElementById("myPicture").src = myPix[randomNum];
		};
	</script>

	<script>
		$(document).ready(function () {
			$('.paperlo button').click(function () {
				$('.papers-container').addClass('papers-selected');
			});
			$('.paperhi button').click(function () {
				$('.papers-container').removeClass('papers-selected');
			});

			$('.awardlo button').click(function () {
				$('.awards-container').addClass('awards-selected');
			});
			$('.awardhi button').click(function () {
				$('.awards-container').removeClass('awards-selected');
			});

			$('.text_container').addClass("hidden");

			$('.text_container').click(function () {
				var $this = $(this);

				if ($this.hasClass("hidden")) {
					$(this).removeClass("hidden").addClass("visible");
					$(this).removeClass("papericon");
				} else {
					$(this).removeClass("visible").addClass("hidden");
				}
			});


		});
	</script>

</head>


<body>
	<div class="content">
		<div id="container">

			<table>
				<tbody>
					<tr>
						<td><img id="myPicture" src="xxx" style="float:left; padding-right:20px" height="200px"></td>
						<script>choosePic();</script>
						<td>
							<div id="DocInfo">
								<h1>Fei Shen (Ê≤àÈ£û)</h1>
								Ph.D. Candidate<br>
								School of Computer Science and Engineering, Nanjing University of Science and Technology<br>
								Office: Room 2003, CSE Building<br>
								Email: feishen_at_njust.edu.cn<br>
								<!-- <a href="TH_CV.pdf" target="_blank" rel="external">CV</a> &bull; -->
								<a href="https://scholar.google.com/citations?user=wqvr28MAAAAJ&hl=en" target="_blank"
									rel="external">Google Scholar</a> &bull; <a href="https://github.com/muzishen" target="_blank"
									rel="external">Github</a><br>
							</div><br>
						</td>
					</tr>
				</tbody>
			</table>
			<br>

			<h2>About Me</h2>
			<!-- <p style="text-align:justify" ;> -->
			<p> Hi üòÑ! I am a member of the <a href="https://imag-njust.net/">Intelligent Media Analysis Group (IMAG)</a>, under the supervision of <a href="https://imag-njust.net/jinhui-tang/">Prof. Jinhui Tang</a>. My research interests lie in <span style="color: red; font-weight: bold;">human-centered controlled and consistent generation</span>, such as <em>pose-guided person generation</em>, <em>virtual dressing/try-on</em>, and <em>talking face</em>. 

I have been relentlessly striving to see humanity achieve digital immortality and machine consciousness at the earliest opportunity. Before this, I was a passionate algorithm competitor, achieving over 50 top-three finishes, including five first-place wins in CCF A Workshops. 

I am fervently dedicated to <span style="text-decoration: underline; font-weight: bold; color: rgb(128, 0, 128);">sharingüå±, collaboratingü§ù, advancingüöÄ, and innovatingüí°</span>. I am deeply passionate about academic research and fully committed to utilizing my research findings to address real-world challenges, thereby making meaningful and impactful contributions to society.

<span style="color: red; font-weight: bold;"><em>If you are interested in collaboration or wish to get in touch with me, please feel free to reach out via email!</em></span> üòä

			</p>

			<h2><span style="color:red;font-size:27px"><strong>NEWS!</strong></span></h2>
			<ul style="height: 200px;overflow-y: auto">
				<div style="text-align: justify; display: block; margin-right: auto;">
					<li>2024/05: We released <a
							href="https://imagdressing.github.io/"><u>IMAGDressing-v1</u></a> for customizable virtual dressing.</li>
					<li>2024/05: We released <a
							href="https://tenvence.github.io/p/v-express/"><u>V-Express</u></a> for portrait video generation.</li>
					<li>2024/02: We released <a
							href="https://github.com/tencent-ailab/PCDMs"><u>PCDMs</u></a> for pose-guided person synthesis.</li>					
					<li>2024/01: One paper was accepted by ICLR 2024.</li>
					<li>2023/08: We won the <a href="./img/ijcai2023.pdf"><u>2nd place</u></a> in Rotated Detection Challenge organized by IJCAI 2023 workshop.</li>
					<li>2023/07: One paper was accepted by by ACM Multmedia 2023.</li>
					<!--<li>2023/04: I was selected for the Rhino-Bird Elite Talent Program by Tencent.</li>-->
					<li>2023/03: We won the <a href="./img/2022_1_nsfc.pdf"><u>1st place</u></a> of Remote Sensing Image
						Segmentation Contest organized by NSFC.</li>
					<li>2023/01: One paper was accepted by by IEEE T-IP (JCR Q1, IF=11.04).</li>
					<li>2022/10: We again won <a href="./img/2022_digix_2nd.pdf"><u>2nd place</u></a> in the Global Campus AI
						Algorithms Challenge organized by HuaWei.</li>
					<li>2022/10: I was selected as the publicity ambassador of the HDC, please watch the <a
							href="https://www.bilibili.com/video/BV1tG411H7qz/?spm_id_from=333.999.0.0&vd_source=ba13dcacc9e5ea26dec3bf70e4e2b19b">videoüòÇ</a>.
					</li>
					<li>2022/05: We won the <a href="./img/2022_cvpr_3rd.jpg"><u>3rd place</u></a> in pet biometric Challenge
						organized by CVPR 2022 workshop.</li>
					<li> 2022/05: We won the <a href="./img/2022_icme_2nd.jpg"><u>2nd place</u></a> in few-shot logo detection
						challenge organized by ICME2022 workshop.</li>
					<li>2022/03: One paper was accepted by ICME2022 (Oral).</li>
					<!--<li>2021/12: ü•á Celebrating a Milestone. My Accumulated Competition Prize Winnings Reach 1,000,000 RMB.</li>-->					
					<li>2021/11: One paper was accepted by BMVC.</li>
					<li> 2021/09: One paper was accepted by IEEE IOTJ (JCR Q1, IF=10.23).</li>
					<li>2021/06: One paper was accepted by IEEE T-ITS (JCR Q1, IF=9.55).</li>
					<li>2020/05: We won the <a href="./img/2020_eccv_1st.pdf"><u>1st place</u></a> in COCO Detection Challenge
						organized by ECCV 2020 workshop.</li>
				</div>
			</ul>

			<h2>Research Experience</h2>


			<div>
				&emsp; <strong>National University of Singapore, Singapore (May 2024 - Present)</strong>
				<img border="0" src="img/NEXT++.png" align="right" width="120" height="60" />
				<ul>
					<li>
						Visiting Research Scholar, <a href="https://www.nextcenter.org/" target="_blank" rel="external">NEXT++</a>
					</li>
					<li>
						Leader: Prof. <a href="https://www.chuatatseng.com/" target="_blank"
							rel="external">Chua Tat-Seng</a>
				
				</ul>
				</li>
				</ul>
			</div>
			
			
			<div>
				&emsp; <strong>Tencent Inc., Shenzhen China (May 2023 - May 2024)</strong>
				<!-- <a href="https://www.smu.edu.sg/" target="_blank" rel="external"> -->
				<img border="0" src="img/ailab.jpg" align="right" width="120" height="60" />
				<!-- </a> -->
				<ul>
					<li>
						Intern, <a href="https://ai.tencent.com" target="_blank" rel="external">AI Lab</a>
					</li>
					<li>
						Leader: Dr. <a href="https://scholar.google.com/citations?user=XGVV3gEAAAAJ&hl=zh-CN&oi=ao" target="_blank"
							rel="external">Xiao Han</a>
					<li>
						Mentor: Dr. <a href="https://junzhang.org/" target="_blank" rel="external">Jun Zhang</a> 
						and <a href="https://scholar.google.com/citations?hl=zh-TW&user=Jh_weSQAAAAJ&view_op=list_works&sortby=pubdate" target="_blank" rel="external">Hu Ye</a>
					</li>
				</ul>
				</li>
				</ul>
			</div>

			<div>
				&emsp; <strong>Nanjing University of Science and Technology, Nanjing China (Sep 2021 - Present)</strong>
				<!-- <a href="https://www.sutd.edu.sg/" target="_blank" rel="external"> -->
				<img border="0" src="img/imag.png" align="right" width="120" height="100" />
				<!-- </a> -->
				<ul>
					<li>
						PhD student, <a href="https://imag-njust.net/" target="_blank" rel="external">IMAG</a>
					</li>
					<li>
						Hosted by Prof. <a href="https://scholar.google.com/citations?user=ByBLlEwAAAAJ&hl=zh-CN" target="_blank"
							rel="external">Jinhui
							Tang</a>,
					<li> Co-supervised by Prof. <a href="https://shuxb104.github.io/" target="_blank" rel="external">Xiangbo
							Shu</a>
						and Assoc Prof. <a href="https://bio.duxy.cc/" target="_blank" rel="external">Xiaoyu Du</a></li>
					</li>
				</ul>
			</div>




			<!-- <h2>Research Interests</h2>

			<ul>
				<h6><strong style="color:#ff0000">Learning From Limited or Imperfect Data</strong></h6>
				<li> Multimedia: Zero/Few-shot Learning, Fine-Grained Visual Classification/Retrieval, ... </li>
				<li> Computer Vision: Multi-Modality Object Localization/Detection/Segmentation </li>
			</ul> -->

			<div class="papers-container papers-selected">
				<h5 class="paperlo">All Publications<button type="button" class="ml-3 btn btn-light">Show selected</button></h5>
				<h5 class="paperhi paperhi-only">Selected Publications<button type="button" class="ml-3 btn btn-light">Show
						all</button></h5>

				<h5 class="pt-2 pb-1">2024</h5>

				<div class="publication media paperhi">
					<div class="media-body">
						<strong>IMAGDressing-v1: Customizable Virtual Dressing</strong><br>
						Fei Shen, Xin Jiang, Xin He, Hu Ye, Cong Wang, Xiaoyu Du, Zechao Li, Jinghui Tang <br>
						Under Review [<a href="https://arxiv.org/pdf/2407.12705" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
								[<a href="https://github.com/muzishen/IMAGDressing">Code</a>]<br>
					</div>
				</div>
				
				<div class="publication media paperhi">
					<div class="media-body">
						<strong>Boosting Consistency in Story Visualization with Rich-Contextual Conditional Diffusion Models</strong><br>
						Fei Shen, Hu Ye, Sibo Liu, Jun Zhang, Cong Wang, Xiao Han, Wei Yang <br>
						Under Review [<a href="https://arxiv.org/pdf/2407.02482" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
								[<a href="https://github.com/muzishen/RCDMs">Code</a>]<br>
					</div>
				</div>
				
				<div class="publication media">
					<div class="media-body">
						V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation</strong></a><br>
						Cong Wang, Kuan Tian, Jun Zhang, Yonghang Guan, Feng Luo, Fei Shen, Zhiwei Jiang, Qing Gu, Xiao Han, Wei Yang <br>
						Under Review
						[<a href="https://arxiv.org/pdf/2406.02511" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/tencent-ailab/V-Express/">Code</a>]<br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						Ensembling Diffusion Models via Adaptive Feature Aggregation</strong></a><br>
						Cong Wang, Kuan Tian, Yonghang Guan, Jun Zhang, Zhiwei Jiang, Fei Shen, Xiao Han, Qing Gu, Wei Yang <br>
						Under Review
						[<a href="https://arxiv.org/pdf/2405.17082" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/tenvence/afa/">Code</a>]<br>
					</div>
				</div>


				<h5 class="pt-2 pb-1">2023</h5>

				<div class="publication media paperhi">
					<div class="media-body">
						<strong>Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models</strong><br>
						Fei Shen, Hu Ye, Jun Zhang, Cong Wang, Xiao Han, Wei Yang <br>
						ICLR 2024 [<a href="https://arxiv.org/pdf/2310.06313.pdf" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
								[<a href="https://github.com/tencent-ailab/PCDMs">Code</a>]<br>
					</div>
				</div>
				
				<div class="publication media paperhi">
					<div class="media-body">
						<strong>Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification</strong><br>
						Fei Shen, Xiaoyu Du, Liyan Zhang, Xiangbo Shu, and Jinhui Tang <br>
						Under Review 
						[<a href="https://arxiv.org/pdf/2301.09498.pdf" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
								[<a href="https://github.com/muzishen/TCRL">Code</a>]<br>
					</div>
				</div>

				<div class="publication media paperhi">
					<div class="media-body">
						<strong>Pedestrian-specific Bipartite-aware Similarity Learning for Text-based Person Retrieval</strong><br>
						Fei Shen, Xiangbo Shu, Xiaoyu Du, and Jinhui Tang <br>
						ACM Multmedia 2023 
						[<a href="https://dl.acm.org/doi/abs/10.1145/3581783.3612009" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
								[<a href="https://github.com/muzishen/PBSL">Code</a>]<br>
					</div>
				</div>



				<div class="publication media paperhi">
					<div class="media-body">
						<strong>GiT: Graph interactive transformer for vehicle re-identification</strong></a><br>
						Fei Shen, Yi Xie, Jianqing Zhu, Xiaobin Zhu, and Huanqiang Zeng <br>
						IEEE Transactions on Image Processing
						[<a href="https://ieeexplore.ieee.org/document/10026500" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/ReID-GiT">Code</a>]
						<br>
					</div>
				</div>

				<h5 class="pt-2 pb-1">2022</h5>
				<div class="publication media">
					<div class="media-body">
						HSGM: A hierarchical similarity graph module for object re-identification</strong></a><br>
						Fei Shen, Xiaoxiao Peng, Lisheng Wang, Xingmeng Hao, Mei Shu, and Yajun Wang <br>
						IEEE ICME 2022 
						[<a href="https://ieeexplore.ieee.org/document/9859883" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/HSGM">Code</a>]<br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						Enhancing part features via contrastive attention module for vehicle re-identification</strong></a><br>
						Manyu Li, Mengwan Wei, Xin He, and Fei Shen* <br>
						IEEE ICIP 2022 
						[<a href="https://ieeexplore.ieee.org/document/9897943" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/HPGN">Code</a>]<br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						A Novel Multi-Frequency Coordinated Module for SAR Ship Detection</strong></a><br>
						Chenchen Qiao, Fei Shen, Xuejun Wang, Ruixin Wang, Fang Cao, Sixian Zhao, and Chang Li <br>
						IEEE ICTAI 2022
						[<a href="https://ieeexplore.ieee.org/document/10097976" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/HPGN">Code</a>]<br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						A sample-proxy dual triplet loss function for object re-identification</strong></a><br>
						Hanxiao Wu, Fei Shen, Jianqing Zhu, Huanqiang Zeng, Xiaobin Zhu, and Zhen Lei <br>
						IET Image Processing
						[<a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/ipr2.12593" target="_blank"
							rel="external"><strong style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/HPGN">Code</a>]<br>
					</div>
				</div>

				<h5 class="pt-2 pb-1">2021</h5>
				<div class="publication media paperhi">
					<div class="media-body">
						<strong>Exploring spatial significance via hybrid pyramidal graph network for vehicle
						re-identification</strong></a><br>
						Fei Shen, Jianqing Zhu, Xiaobin Zhu, Yi Xie, and Jingchang Huang <br>
						IEEE Transactions on Intelligent Transportation Systems
						[<a href="https://ieeexplore.ieee.org/document/9457192" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/HPGN">Code</a>]<br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						<strong>An efficient multiresolution network for vehicle reidentification</strong></a><br>
						Fei Shen, Jianqing Zhu, Xiaobin Zhu, Jingchang Huang, Huanqiang Zeng, Zhen Lei, and Canhui Cai <br>
						IEEE Internet of Things Journal
						[<a href="https://ieeexplore.ieee.org/document/9569744" target="_blank" rel="external"><strong
								style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/EMRN">Code</a>]<br>
					</div>
				</div>

				
				<div class="publication media">
					<div class="media-body">
						Object Re-identification Using Teacher-Like and Light Students</strong></a><br>
						Yi Xie, Hanxiao Wu, Fei Shen, Jianqing Zhu, and Huanqiang Zeng <br>
						BMVC 2021
						[<a href="https://www.bmvc2021-virtualconference.com/assets/papers/1193.pdf" target="_blank"
							rel="external"><strong style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/EMRN">Code</a>]<br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						Viewpoint robust knowledge distillation for accelerating vehicle re-identification</a><br>
						Yi Xie, Fei Shen, Jianqing Zhu, and Huanqiang Zeng <br>
						EURASIP Journal on Advances in Signal Processing
						[<a href="https://link.springer.com/article/10.1186/s13634-021-00767-x" target="_blank"
							rel="external"><strong style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/EMRN">Code</a>]<br>
					</div>
				</div>
			</div>



			<!--<sup>&#x2709</sup>-->
			<div class="awards-container awards-selected">
				<h5 class="awardlo">All Awards<button type="button" class="ml-3 btn btn-light">Show selected</button>
				</h5>
				<h5 class="awardhi awardhi-only">Selected Awards<button type="button" class="ml-3 btn btn-light">Show
						all</button></h5>

				<h5 class="pt-2 pb-1">2023 </h5>

				<!-- <div class="publication media">
					<div class="media-body">
						Object Re-identification Using Teacher-Like and Light Students</strong></a><br>
						Yi Xie, Hanxiao Wu, Fei Shen, Jianqing Zhu, and Huanqiang Zeng <br>
						BMVC 2021 
						[<a href="https://www.bmvc2021-virtualconference.com/assets/papers/1193.pdf" target="_blank" rel="external"><strong style="color:darkblue"></strong>PDF</a>]
						[<a href="https://github.com/muzishen/EMRN">Code</a>]<br>
					</div>
				</div> -->
				
				<div class="publication media awardhi">
					<div class="media-body">
						IJCAI 2023 Workshop Challenge, Track IIÔºöRotated Detection, Runner-up </a><br>
						Zijun Huang and Fei Shen <br>
						Organizer: IJCAI <br>
					</div>
				</div>
				
				<div class="publication media awardhi">
					<div class="media-body">
						2022-2023‚ÄúËà™Â§©ÂÆèÂõæÊùØ‚ÄùÈÅ•ÊÑüÂΩ±ÂÉèÊô∫ËÉΩÂ§ÑÁêÜÁÆóÊ≥ïÂ§ßËµõ-ÈÅ•ÊÑüÂΩ±ÂÉèËØ≠‰πâÂàÜÂâ≤,‰∏ÄÁ≠âÂ•ñ</a><br>
						ÈªÑÊ¢ìÈíß, ÁéãÊô®Êòä, ‰ΩïÂÖ∏, ÊùéËã±Èæô, Ê≤àÈ£û<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂõΩÂÆ∂Ëá™ÁÑ∂ÁßëÂ≠¶Âü∫ÈáëÂßîÂëò‰ºö‰ø°ÊÅØÁßëÂ≠¶ÈÉ® <br>
					</div>
				</div>
				
				<div class="publication media">
					<div class="media-body">
						2023ÂõΩÈôÖÂ§ßÊï∞ÊçÆ‰∫ß‰∏öÂçöËßà‰ºö-ÁîüÊ¥ªÂûÉÂúæÊ£ÄÊµã,‰∫åÁ≠âÂ•ñ</a><br>
						Ê±üËàí, ÊàøÊ¢ìÊôî, ‰ªòÂ≠ùÂæ∑, Ê≤àÈ£û  <br>
						‰∏ªÂäûÂçï‰ΩçÔºöË¥µÈò≥Â§ßÊï∞ÊçÆ‰∫§ÊòìÊâÄ <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2023IEEE IGRSS Data Fusion Contest Track 1, 3rd place</a><br>
						Jiarui Hu, Zijun Huang, and Fei Shen<br>
						Organizer: IEEE IGRSS<br>
					</div>
				</div>

				<h5 class="pt-2 pb-1">2022 </h5>



				<div class="publication media">
					<div class="media-body">
						2022ÁßëÂ§ßËÆØÈ£û1024ÊåëÊàòËµõ,2‰∏™ÂÜ†ÂÜõ;1‰∏™‰∫öÂÜõ;1‰∏™Â≠£ÂÜõ</a><br>
						Ê≤àÈ£û, ‰ªª‰øäÂºõ, ËíãÈë´, ‰ªòÂ≠ùÂæ∑, Ê±üËàí, ÊàøÊ¢ìÊôî, È≠èÊ¢¶Â©â<br>
						Âü∫‰∫éÂèØËßÅÂÖâÂõæÂÉèÁöÑÊüëÊ©òËä±ÊûúÊ¢¢ËØÜÂà´ÊåëÊàòËµõ, Á¨¨‰∏ÄÂêç<br>
						Ëæ£Ê§íÁóÖËô´ÂÆ≥ÂõæÂÉèËØÜÂà´ÊåëÊàòËµõ, Á¨¨‰∏ÄÂêç<br>
						Êô∫ËÉΩÁ°¨‰ª∂ËØ≠Èü≥ÊéßÂà∂ÁöÑÊó∂È¢ëÂõæÂàÜÁ±ªÊåëÊàòËµõ 2.0, Á¨¨‰∫åÂêç<br>
						Âü∫‰∫éÂ∞èÊ†∑Êú¨ÁöÑÂºÇÂ∏∏Ê£ÄÊµã‰ªªÂä°ÊåëÊàòËµõ, Á¨¨‰∏âÂêç<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÁßëÂ§ßËÆØÈ£û <br>
			
					</div>
				</div>



				<div class="publication media">
					<div class="media-body">
						2022 ÂÖ®ÂõΩÂ§ßÂ≠¶ÁîüÁâ©ËÅîÁΩëËÆæËÆ°Á´ûËµõ,‰∏ÄÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, ËíãÈë´, ‰ªòÂ≠ùÂæ∑, ÈôàÂòâÁÖú<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂÖ®ÂõΩÈ´òÁ≠âÂ≠¶Ê†°ËÆ°ÁÆóÊú∫ÊïôËÇ≤Á†îÁ©∂‰ºö <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2022 kaggle ÂæÆÁîüÁâ©ÁõÆÊ†áÊ£ÄÊµã,Á¨¨‰∏ÄÂêç</a><br>
						‰∏ªÂäûÂçï‰ΩçÔºökaggle <br>
						Ê≤àÈ£û<br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2022Âçé‰∏∫digixÂÖ®ÁêÉÊ†°Âõ≠Á≤æËã±ÊåëÊàòËµõ-ËΩ¶ÈÅìÁ∫øÊ∏≤ÊüìÊ£ÄÊµã,<a href="img/2022_digix_2nd.pdf">‰∫öÂÜõ</a><br>
						Ê≤àÈ£û, ËíãÈë´, ÈôàÂòâÁÖú [<a href="https://github.com/muzishen/Pet-ReID-IMAG">Code</a>] <br>
						‰∏ªÂäûÂçï‰ΩçÔºöÊ±üËãèÁúÅ‰∫∫Â∑•Êô∫ËÉΩÂ≠¶‰ºö, Âçé‰∏∫ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏ <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2022 few-shot logo detection challenge of ICME workshop, 2nd place</a><br>
						Zhe Wang, Baoying Chen, and Fei Shen<br>
						OrganizerÔºöIEEE ICME <br>
					</div>
				</div>


				<div class="publication media">
					<div class="media-body">
						2022È¶ñÂ±ä‚ÄúÂÖ¥Êô∫ÊùØ‚ÄùÂÖ®ÂõΩ‰∫∫Â∑•Êô∫ËÉΩÂàõÊñ∞Â∫îÁî®Â§ßËµõ, ‰∏âÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, ËíãÈë´, ÁéãÊôã, ‰ΩïÊù®Âáå<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂÖ®ÂõΩ‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºö <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2022ËàπÊµ∑Êï∞ÊçÆÂ∫îÁî®ÂàõÊñ∞Â§ßËµõ-Êµ∑‰∏äÁõÆÊ†áÊ£ÄÊµã, ‰∏âÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, ÈªÑÊ¢ìÈíß<br>
						‰∏ªÂäûÂçï‰ΩçÔºö‰∏≠ÂõΩËàπËà∂ÈõÜÂõ¢, Ê∑±Êµ∑ÁßëÂ≠¶ÊäÄÊúØÂ§™ÊπñÂÆûÈ™åÂÆ§ <br>
					</div>
				</div>


				<div class="publication media">
					<div class="media-body">
						2022 IEEE UV ‚ÄúVision Meets Algae‚Äù Object Detection Challenge, 3rd
							place</a><br>
						Xiaode Fu and Fei Shen<br>
						OrganizerÔºöIEEE UV <br>
					</div>
				</div>



				<div class="publication media awardhi">
					<div class="media-body">
						2022 pet biometric Challenge of CVPR workshop, 3rd place</a><br>
						Fei Shen, Zhe Wang, Zijun Huang, Xiaode Fu, and Jiayi Chen<br>
						[<a href="https://github.com/muzishen/Pet-ReID-IMAG">Code</a>]
						OrganizerÔºöCVPR <br>
					</div>
				</div>



				<h5 class="pt-2 pb-1">2021 </h5>

				<div class="publication media">
					<div class="media-body">
						2021Âçé‰∏∫‰∫ë‚Äú‰∏úÂê¥ÊùØ‚ÄùÊï∞Â≠óËΩ¨ÂûãÂàõÊñ∞Â§ßËµõ-Ê±ΩËΩ¶Èõ∂ÈÉ®‰ª∂Ê£ÄÊµã,‰∏ÄÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û <br>
						‰∏ªÂäûÂçï‰ΩçÔºöËãèÂ∑ûÂ∏ÇÊîøÂ∫ú, Âçé‰∏∫ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏ <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2021Êµ∑Ê¥ãÁõÆÊ†áÊô∫ËÉΩÊÑüÁü•ÂõΩÈôÖÊåëÊàòËµõ-ÂèØËßÅÂÖâÁõÆÊ†áÊ£ÄÊµã,‰∏ÄÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, Ë∞¢Êáø, Âê¥Âê´Á¨ë<br>
						‰∏ªÂäûÂçï‰ΩçÔºö‰∏≠ÂõΩÈÄ†ËàπÂ∑•Á®ãÂ≠¶‰ºö, ÂõΩÈôÖËàπËà∂‰∏éÊµ∑Ê¥ãÂ∑•Á®ãÂàõÊñ∞‰∏éÂêà‰ΩúËÅîÁõü(ICNAME), ‰∏≠ÂõΩÂõæË±°ÂõæÂΩ¢Â≠¶Â≠¶‰ºö<br>
					</div>
				</div>


				<div class="publication media">
					<div class="media-body">
						2021Á¶èÂª∫ÁúÅËΩØ‰ª∂ËÆæËÆ°Â§ßËµõ,‰∏ÄÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÁ¶èÂª∫ÁúÅÂ∑•‰∏öÂíå‰ø°ÊÅØÂåñÂéÖ <br>
					</div>
				</div>


				<div class="publication media">
					<div class="media-body">
						2021ÁßëÂ§ßËÆØÈ£û1024ÊåëÊàòËµõ,3‰∏™ÂÜ†ÂÜõ;1‰∏™‰∫öÂÜõ</a><br>
						Ê≤àÈ£û, Ë∞¢Êáø, ‰ΩïÊñ∞, ‰Ωï‰ºØÂãá<br>
						ÊüëÊ©òÁóÖËô´ÂÆ≥ËØÜÂà´ÊåëÊàòËµõ, Á¨¨‰∏ÄÂêç<br>
						ÈÅ•ÊÑüÂΩ±ÂÉèÂÖ∏ÂûãÁõÆÊ†áÊèêÂèñÊåëÊàòËµõ, Á¨¨‰∏ÄÂêç<br>
						ÂÜú‰ΩúÁâ©ÁîüÈïøÊÉÖÂÜµËØÜÂà´ÊåëÊàòËµõ, Á¨¨‰∏ÄÂêç<br>
						Âè∂ËèúÁóÖËô´ÂÆ≥ÂõæÂÉèËØÜÂà´ÊåëÊàòËµõ, Á¨¨‰∫åÂêç<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÁßëÂ§ßËÆØÈ£û <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2021ÂÖ®ÂõΩÈ´òÊ†°Êñ∞ÊòüÊåëÊàòËµõ-‰ºÅ‰∏öÂá∫È¢ò,Êè≠Ê¶úÊåÇÂ∏Ö, ÂèåËµõÈÅì‰∏ÄÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û<br>
						ÊòüÂÆ∏ÁßëÊäÄËΩªÈáèÂåñ‰∫∫ËÑ∏Ê£ÄÊµãÁ¨¨‰∏ÄÂêç<br>
						‰∫øËÅîÁßëÊäÄÂÆ§ÂÜÖË°å‰∫∫Ë∑üË∏™Á¨¨‰∏ÄÂêç<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂé¶Èó®Â∑•‰∏öÂíå‰ø°ÊÅØÂåñÂ±Ä <br>
					</div>
				</div>


				<div class="publication media">
					<div class="media-body">
						2021‚ÄúÊòìÂçéÂΩï‚ÄùÊùØÂõæÂÉèÊèèËø∞ÁîüÊàê, Á¨¨‰∫åÂêç</a><br>
						‰ΩïÊñ∞, Ê≤àÈ£û<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂ§©Ê¥•Â∑•‰∏öÂíå‰ø°ÊÅØÂåñÂ±Ä, Âåó‰∫¨ÊòìÂçéÂΩï‰ø°ÊÅØÊäÄÊúØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏ <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2021‰∏≠ÂõΩËΩØ‰ª∂ÊùØ-ËΩØ‰ª∂ËÆæËÆ°Â§ßËµõ, ‰∫åÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, Ë∞¢Êáø, Âê¥Âê´Á¨ë [<a href="https://github.com/muzishen/China-Software-Cup">Code</a>]<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂ∑•‰∏öÂíå‰ø°ÊÅØÂåñÈÉ® <br>
					</div>
				</div>


				<div class="publication media">
					<div class="media-body">
						2021ÂÖ®ÂõΩ‰∫∫Â∑•Êô∫ËÉΩÂàõÊñ∞(AIAC)Â∫îÁî®Â§ßËµõ-Èí¢ÈìÅÁëïÁñµÊ£ÄÊµã, ‰∫åÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û<br>
						‰∏ªÂäûÂçï‰ΩçÔºö‰∏≠ÂõΩ‰∫∫Â∑•Êô∫ËÉΩÂ≠¶‰ºö <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2021ÂÖ®ÂõΩÊï∞Â≠óÁîüÊÄÅÂàõÊñ∞Â§ßËµõ-Êô∫ËÉΩÁÆóÊ≥ïËµõ, Á¨¨‰∏âÂêç</a><br>
						‰ΩïÊñ∞, Ê≤àÈ£û, ÈÉùÂÖÉÊ¥Å<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂ§©Ê±† <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						WAIC‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºö-ÁÆóÊ≥ïÊâ©Â±ïÊåëÊàòËµõ, Â≠£ÂÜõ</a><br>
						Ê≤àÈ£û<br>
						‰∏ªÂäûÂçï‰ΩçÔºöWAIC <br>
					</div>
				</div>


				<div class="publication media">
					<div class="media-body">
						2021‚ÄúÊòáËÖæÊùØ‚ÄùÈÅ•ÊÑüÂΩ±ÂÉèÊô∫ËÉΩÂ§ÑÁêÜÁÆóÊ≥ïÂ§ßËµõ-ÁªÜÁ≤íÂ∫¶ËØ≠‰πâÂàÜÂâ≤, ‰∏âÁ≠âÂ•ñ</a><br>
						ËµµÊÖßÁê≥, Âé¶ËÅ™, ‰ΩïÊ¨£, Ê≤àÈ£û<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂõΩÂÆ∂Ëá™ÁÑ∂ÁßëÂ≠¶Âü∫ÈáëÂßîÂëò‰ºö‰ø°ÊÅØÁßëÂ≠¶ÈÉ® <br>
					</div>
				</div>


				<div class="publication media">
					<div class="media-body">
						2021Êµ∑Ê¥ãÁõÆÊ†áÊô∫ËÉΩÊÑüÁü•ÂõΩÈôÖÊåëÊàòËµõ-Á∫¢Â§ñÁõÆÊ†áÊ£ÄÊµã, ‰∏âÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, Ë∞¢Êáø, Âê¥Âê´Á¨ë<br>
						‰∏ªÂäûÂçï‰ΩçÔºö‰∏≠ÂõΩÈÄ†ËàπÂ∑•Á®ãÂ≠¶‰ºö, ÂõΩÈôÖËàπËà∂‰∏éÊµ∑Ê¥ãÂ∑•Á®ãÂàõÊñ∞‰∏éÂêà‰ΩúËÅîÁõü(ICNAME), ‰∏≠ÂõΩÂõæË±°ÂõæÂΩ¢Â≠¶Â≠¶‰ºö <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2022 ÂÖ®ÂõΩÊ∞¥‰∏ãÂÖâÂ≠¶ÁõÆÊ†áÊ£ÄÊµãÊô∫ËÉΩÁÆóÊ≥ïËµõ, ÂÖ•Âõ¥Â•ñ</a><br>
						‰ΩïÊñ∞ÔºåÊ≤àÈ£û, ÊùéËß£<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂõΩÂÆ∂Ëá™ÁÑ∂ÁßëÂ≠¶Âü∫ÈáëÂßîÂëò‰ºö‰ø°ÊÅØÁßëÂ≠¶ÈÉ® <br>
					</div>
				</div>

				<h5 class="pt-2 pb-1">2020</h5>


				<div class="publication media awardhi">
					<div class="media-body">
						2020 Visual Inductive Priors for Data-Efficient Computer Vision Object Detection of ECCV workshop, 1st place</a><br>
						Fei Shen [<a href="https://github.com/muzishen/VIPriors-Object-Detection-Challenge">Code</a>]<br>
						OrganizerÔºöECCV <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2020‰∏≠ÂõΩËΩØ‰ª∂ÊùØ-ËΩØ‰ª∂ËÆæËÆ°Â§ßËµõ, ‰∏ÄÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, Ë∞¢Êáø, È≠èÊ¢¶Â©â [<a href="https://github.com/muzishen/China-Software-Cup">Code</a>]<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂ∑•‰∏öÂíå‰ø°ÊÅØÂåñÈÉ® <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2020 ÊòìÂçéÂΩï‰∏çÂÆöÂêëÁÆóÊ≥ïËµõ, ‰∫åÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, ‰ΩïÊñ∞, ÊûóÂï∏Ê∂õ<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÂ§©Ê¥•Â∑•‰∏öÂíå‰ø°ÊÅØÂåñÂ±Ä, Âåó‰∫¨ÊòìÂçéÂΩï‰ø°ÊÅØÊäÄÊúØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏ <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2020 Âçé‰∏∫digixÂÖ®ÁêÉÊ†°Âõ≠Á≤æËã±ÊåëÊàòËµõ-Êï∞Á†ÅÊ£ÄÁ¥¢,Á¨¨ÂõõÂêç</a><br>
						Ê≤àÈ£û, Ë∞¢Êáø, ‰ΩïÊñ∞ [<a href="https://github.com/muzishen/Huawei_Digix_Retrieval_Top4">Code</a>]<br>
						‰∏ªÂäûÂçï‰ΩçÔºöÊ±üËãèÁúÅ‰∫∫Â∑•Êô∫ËÉΩÂ≠¶‰ºö, Âçé‰∏∫ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏ <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2020‚Äú‰∏≠ÂÖ¥ÊçßÊúà‚ÄùÁÆóÊ≥ïÂ§ßËµõ-Â§öÁõÆÊ†áË∑üË∏™, ‰ºòËÉúÂ•ñ</a><br>
						Ê≤àÈ£û [<a href="https://github.com/muzishen/Deepsort_V2">Code</a>] <br>
						‰∏ªÂäûÂçï‰ΩçÔºö‰∏≠ÂÖ¥ÈÄöËÆØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏ <br>
					</div>
				</div>

				<div class="publication media">
					<div class="media-body">
						2020 ‚ÄúÂçé‰∏∫ÊùØ‚ÄùÁ¨¨‰∫åÂ±ä‰∏≠ÂõΩÁ†îÁ©∂Áîü‰∫∫Â∑•Êô∫ËÉΩÂàõÊñ∞Â∫îÁî®Â§ßËµõ-Â∞èÊ†∑Êú¨ÂàÜÁ±ª, ‰∏âÁ≠âÂ•ñ</a><br>
						Ê≤àÈ£û, Ë∞¢Êáø, ‰ΩïÊñ∞<br>
						‰∏ªÂäûÂçï‰ΩçÔºö‰∏≠ÂõΩÂ≠¶‰Ωç‰∏éÁ†îÁ©∂ÁîüÊïôËÇ≤Âçè‰ºö <br>
					</div>
				</div>
			</div>




<h2>Honors</h2>
<div>
    <ul>
		<li>Âçó‰∫¨ÁêÜÂ∑•Â§ßÂ≠¶‰ºòÁßÄÂçöÂ£´ÁîüÂüπÂÖªËÆ°Âàí, Âçó‰∫¨ÁêÜÂ∑•Â§ßÂ≠¶, 2024</li>
		<li>Outstanding Scholarship of 2024 Tencent Rhino-bird Research Elite Program, Tencent, 2024</li>
		<li>Ê±üËãèÁúÅ‰∏âÂ•ΩÂ≠¶Áîü, Ê±üËãèÁúÅÊïôËÇ≤ÂéÖ, 2024</li>
        <li>Ê†°ÈïøÂ•ñÁ´†, Âçó‰∫¨ÁêÜÂ∑•Â§ßÂ≠¶, 2023</li>
        <li>Á†îÁ©∂ÁîüÂõΩÂÆ∂Â•ñÂ≠¶Èáë, ‰∏≠ÂõΩÊïôËÇ≤ÈÉ®, 2023</li>
        <li>ÂÖ•ÈÄâÂõΩÂÆ∂ÂÖ¨Ê¥æÂá∫ÂõΩÁïôÂ≠¶È°πÁõÆ, ÂõΩÂÆ∂ÁïôÂ≠¶Âü∫ÈáëÁÆ°ÁêÜÂßîÂëò‰ºö, 2023</li>
        <li>ÂÖ•ÈÄâÂçé‰∏∫ÂºÄÂèëËÄÖÁîüÊÄÅÂèëÂ±ïÁâπÊÆäË¥°ÁåÆÂ•ñ, Âçé‰∏∫ÂºÄÂèëËÄÖÂ§ß‰ºö, 2023</li>
        <li>ÂÖ•ÈÄâËÖæËÆØÁäÄÁâõÈ∏üÁ≤æËã±‰∫∫ÊâçËÆ°Âàí, ËÖæËÆØ, 2023</li>
		<li>Kaggle Master, Kaggle, 2022</li>
        <li>First Prize Scholarship of Nanjing University of Science and Technology, 2021, 2022, 2023</li>
        <li>Á†îÁ©∂ÁîüÂõΩÂÆ∂Â•ñÂ≠¶Èáë, ‰∏≠ÂõΩÊïôËÇ≤ÈÉ®, 2021</li>
        <!-- <li>First-class Innovation Scholarship, Ministry of Industry and Information Technology of China, 2017</li> -->
    </ul>
</div>

<h2>Professional Services</h2>
<div>
    <ul>
        <li>
            <b>Journal Reviewer</b>: <br>
            &emsp; ‚Ä¢ T-IP | T-ITS | T-VT | T-NNLS | T-AI | T-CSVT | IOTJ | NCA | NC <br>
        </li>
        <li>
            <b>Conference Reviewer / Program Committee Member</b>: <br>
            &emsp; ‚Ä¢ NIPS | ICML | CVPR | ECCV | ICCV | MICCAI | ACM MM | ICME <br>
        </li>
    </ul>
</div>

<h2>Others</h2>
<div>
    <ul>
       In my free time, I enjoy activities such as running, playing soccer, and basketball. Additionally, I have undergone brief professional training in table tennis.</li>
    </ul>
</div>


</body>

</html>
